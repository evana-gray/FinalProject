---
title: "Modeling"
format: html
editor: visual
---

This section of the project will focus on fitting statistical models to our dataset in hopes of being able to take in new information about an individual and predict if they have diabetes. A classification tree model and a random forest model, both of differing tuning parameters, will be compared to each other to determine which is more accurate. The initial steps will be the same as the EDA section - the data must be read in and factors will be created for our categorical variables.

```{r}
library(tidyverse)
library(tidymodels)
library(rsample)
library(parsnip)
library(tree)
library(rpart)
library(rpart.plot)
library(baguette)
library(ranger)
library(yardstick)
library(future)

#set seed for repeatable results where randomization occurs. 
set.seed(16)

#this command allows for parallel computing and faster run times
plan(multisession, workers = 14)
```

# Read Data

```{r}
diabetes <- read_csv("diabetes_binary_health_indicators_BRFSS2015.csv")

#convert col names to lower case for easy reference
colnames(diabetes) <- tolower(colnames(diabetes))
```

# Create Factors

```{r}
diabetes <- diabetes |>
  mutate(
    diabetes_binary_f = factor(diabetes_binary, levels = c(0,1),
                               labels = c("no diabetes", "diabetes")), 
    highbp_f = factor(highbp, levels = c(0,1),
                               labels = c("no high BP", "high BP")),
    highchol_f = factor(highchol, levels = c(0,1),
                               labels = c("no high cholesterol", "high cholesterol")),
    cholcheck_f = factor(cholcheck, levels = c(0,1),
                               labels = c("no cholesterol check in 5 years", "yes cholesterol check in 5 years")),
    smoker_f = factor(smoker, levels = c(0,1),
                               labels = c("no", "yes")), 
    stroke_f = factor(stroke, levels = c(0,1),
                               labels = c("no", "yes")),
    heartdiseaseorattack_f = factor(heartdiseaseorattack, levels = c(0,1),
                               labels = c("no", "yes")),
    physactivity_f = factor(physactivity, levels = c(0,1),
                               labels = c("no", "yes")),
    fruits_f = factor(fruits, levels = c(0,1),
                               labels = c("no","yes")),
    veggies_f = factor(veggies, levels = c(0,1),
                               labels = c("no", "yes")),
    hvyalcoholconsump_f = factor(hvyalcoholconsump, levels = c(0,1),
                               labels = c("no", "yes")),
    anyhealthcare_f = factor(anyhealthcare, levels = c(0,1),
                               labels = c("no", "yes")),
    nodocbccost_f = factor(nodocbccost, levels = c(0,1),
                               labels = c("no","yes")),
    genhlth_f = factor(genhlth, levels = 1:5,
                               labels = c("excellent", "very good", "good", "fair", "poor")),
    diffwalk_f  = factor(diffwalk, levels = c(0,1),
                               labels = c("no", "yes")),
    sex_f = factor(sex, levels = c(0,1),
                               labels = c("female", "male")),
    age_f = factor(age, levels = 1:13,
                        labels = c("18 to 24",
                          "25 to 29", 
                          "30 to 34", 
                          "35 to 39",
                          "40 to 44",
                          "45 to 49",
                          "50 to 54",
                          "55 to 59",
                          "60 to 64",
                          "65 to 69",
                          "70 to 74",
                          "75 to 79", 
                          "80 to high"
                   )),
    education_f = factor(education, levels = 1:6,
                         labels = c("Never attended school or only kindergarten",
                         "Grades 1 through 8 (Elementary)",
                         "Grades 9 through 11 (Some high school)",
                         "Grade 12 or GED (High school graduate)",
                         "College 1 year to 3 years (Some college or technical school)",
                         "College 4 years or more (College graduate)")
                         ),
    income_f = factor(income, levels = 1:8,
                      labels = c("< 10k",
                                "< 15k",
                                "< 20k",
                                "< 25k",
                                "< 35k",
                                "< 50k",
                                "< 75k",
                                "75k+"))
  )
```

# Subset Variables of Interest

First, we will include only the variables needed for training and testing. The full dataset is removed due to save memory.

```{r}
diabetes_model_data <- diabetes |>
  select(diabetes_binary_f, highbp_f, sex_f, income_f, age_f, bmi)
rm(diabetes) #remove large original file
```

# Split Data And Fold

In this step we will split the original dataset such that 70% of records are placed in the training set and 30% of records go into the testing set. The testing set records will be introduced in our final model evaluations. For fitting purposes the training samples will be used.

We will also create 5 cross validation folds using the training dataset.

```{r}

diabetes_split <- rsample::initial_split(diabetes_model_data, prop = .7)
diabetes_train <- rsample::training(diabetes_split)
diabetes_test <- rsample::testing(diabetes_split)

diabetes_cv_folds <- vfold_cv(diabetes_train, 5)

```

# Recipe

The recipe step allows us to explicitly lay out data preparation steps such as normalizing or transforming data, creating dummy variables, and letting R know what data is an outcome variable. R stores the recipe in a way that it can be easily repeated as often as needed.

```{r}
reci_1 <- recipe(diabetes_binary_f~ ., data = diabetes_train) |>
  step_normalize(all_numeric(), -diabetes_binary_f) |>
  update_role(diabetes_binary_f, new_role = "outcome") |>
  step_dummy(highbp_f, sex_f, income_f, age_f)


reci_1 |>
  prep(diabetes_train) |>
  bake(diabetes_train) |>
  colnames() 

```

# Classification Tree Models

Classification tree models are a tree based model used to fit data with categorical outcomes or where more data modeling flexibility in modeling is useful. Relationships are not always linear, or resemble a function that quadratic terms could approximate, in these instances a tree model is needed that can use discrete prediction regions in its estimation.

Classification trees resemble a tree (upside-down usually) where the root is representative of all data. From there, recursive binary splitting is used to identify what variables are most predictive of an outcome and what values of that variable are most predictive at a given point. All possibilities are considered and the dataset is split into two branches at that point when loss-function results are minimized. This process is repeated at every branch until the algorithm is complete.

In this analysis we will use five fold cross-validation to tune our model hyperparameters such as the number of branches and cost complexity. In this process our existing dataset is split into several (k) separate datasets, or folds, and our model is trained on each fold and the error from each fold's fitting are measured. Note that the dataset that gets folded does not include any records that we will later use to test the model (the vfold_cv() function above is applied to the training split).

The resulting tree can be read by a series of if-then questions, e.g. "is BMI \< 27?", if yes move to one node, if no move to another node and the process is repeated until at the final branch a prediction is made - "no diabetes" or "diabetes".

```{r}
# Define models
class_tree_mod <- decision_tree(tree_depth = tune(),
                                min_n = 20,
                                cost_complexity = tune()) |>
  set_engine("rpart") |>
  set_mode("classification")

#set up workflow
class_tree_flow <- workflow() |>
  add_recipe(reci_1) |>
  add_model(class_tree_mod)

#fit grids with multiple level parameters
fit1_grid <- grid_regular(cost_complexity(),
                           tree_depth(), 
                           levels = 2)
fit2_grid <- grid_regular(cost_complexity(),
                           tree_depth(), 
                           levels = 3)
fit3_grid <- grid_regular(cost_complexity(),
                           tree_depth(), 
                           levels = 5)
                          

#fit trees to CV fold
fit1 <- class_tree_flow |>
  tune_grid(resamples = diabetes_cv_folds,
            grid = fit1_grid,
            metrics = metric_set(mn_log_loss)
            )
fit2 <- class_tree_flow |>
  tune_grid(resamples = diabetes_cv_folds,
            grid = fit2_grid,
            metrics = metric_set(mn_log_loss)
            )
fit3 <- class_tree_flow |>
  tune_grid(resamples = diabetes_cv_folds,
            grid = fit3_grid,
            metrics = metric_set(mn_log_loss)
            )

#review model parameters
fits1_parameters <- fit1 |>
  collect_metrics() |>
  filter(.metric == "mn_log_loss") |>
  arrange(mean)

fits2_parameters <- fit2 |>
  collect_metrics() |>
  filter(.metric == "mn_log_loss") |>
  arrange(mean)

fits3_parameters <- fit3 |>
  collect_metrics() |>
  filter(.metric == "mn_log_loss") |>
  arrange(mean)

fits1_parameters
fits2_parameters
fits3_parameters

tree_results <- rbind(
  show_best(fit1, metric = "mn_log_loss", n = 1), # best metric for levels = 2
  show_best(fit2, metric = "mn_log_loss", n = 1), # best metric for levels = 3
  show_best(fit3, metric = "mn_log_loss", n = 1) # best metric for levels = 5 -- this is the model with the lowest mean log loss
)
tree_results

#select best fit
class_lowest_log <- select_best(fit3)
class_lowest_log

```

# Random Forest Models

The Random Forest model is similar to the Classification Tree and can similarly handle classification and regression to make predictions but differs in some important methods. A random forest model uses bootstrapping or "bagging" in which the original training dataset is resampled **with replacement** many times. This means a single observation can appear in a bootstrapped sample multiple times. For each bootstrapped sample a tree model is fit. For each tree model, a random subset of variables are included and this helps ensure the model is not over fit to the training data as classification trees can often choose the same variables in the same order of split. As a result the trees are less similar to each other and there is a reduction in overall model variance.

Each tree fit within a model makes a different prediction and the overall prediction is determined by a "majority vote" (most common prediction) in classification scenarios, or a numeric average in regression scenarios.

Another key element of Random Forest modeling is the concept of out-of-bag observations. These are observations that are left out of each bootstrap sample. They can act as a defacto test set for trees not fit on them. This makes cross validation somewhat unncessary in random forest modeling. Regardless, cross validation was also used in fitting the random forest models below.

The number of variables selected at each tree is the "mtry" hyperparameter. In the models below this value is varied in levels 2, 4 and 5. The number of trees to fit for each model is set at 100.

```{r}

#define RF model
rf1_diabetes <- rand_forest(mtry = 2, trees = 100) |>
  set_engine("ranger") |>
  set_mode("classification")

rf2_diabetes <- rand_forest(mtry = 4, trees = 100) |>
  set_engine("ranger") |>
  set_mode("classification")

rf3_diabetes <- rand_forest(mtry = 5, trees = 100) |>
  set_engine("ranger") |>
  set_mode("classification")


#set up workflow
rf1_flow <- workflow() |>
  add_recipe(reci_1) |>
  add_model(rf1_diabetes)

rf2_flow <- workflow() |>
  add_recipe(reci_1) |>
  add_model(rf2_diabetes)

rf3_flow <- workflow() |>
  add_recipe(reci_1) |>
  add_model(rf3_diabetes)



#fit RF to CV folds

rf1_fit <- rf1_flow |>
  tune_grid(resamples = diabetes_cv_folds,
            metrics = metric_set(mn_log_loss)
            )

rf2_fit <- rf2_flow |>
  tune_grid(resamples = diabetes_cv_folds,
            metrics = metric_set(mn_log_loss)
            )

rf3_fit <- rf3_flow |>
  tune_grid(resamples = diabetes_cv_folds,
            metrics = metric_set(mn_log_loss)
            )

# find best parameters
rf1_fits_parameters <- rf1_fit |>
  collect_metrics() |>
  filter(.metric == "mn_log_loss") |>
  arrange(mean)

rf2_fits_parameters <- rf2_fit |>
  collect_metrics() |>
  filter(.metric == "mn_log_loss") |>
  arrange(mean)

rf3_fits_parameters <- rf3_fit |>
  collect_metrics() |>
  filter(.metric == "mn_log_loss") |>
  arrange(mean)


 rf1_fits_parameters # mtry= 2
 rf2_fits_parameters # mtry = 4
 rf3_fits_parameters # mtry = 5 -- this is the model with the lowest mean log loss

 rf3_lowest_log <- select_best(rf3_fit)
 rf3_lowest_log

```

# Best Models on Full Split Dataset

```{r}
#Classification Tree - model 3 levels = 5
class_tree_flow2 <- class_tree_flow |>
  finalize_workflow(class_lowest_log)

class_final_fit <- class_tree_flow2 |>
  last_fit(diabetes_split, metrics = metric_set(accuracy, mn_log_loss))

collect_metrics(class_final_fit)


#Random Forest - model 3 mtry = 5
rf3_flow2 <- rf3_flow |> 
  finalize_workflow(rf3_lowest_log)

rf3_final_fit <- rf3_flow2 |>
  last_fit(diabetes_split, metrics = metric_set(accuracy, mn_log_loss))

collect_metrics(rf3_final_fit)


```

#Overall Best Model

The overall best model, with the lowest mn_log_loss is the random forest with a mn_log_loss of 0.336.

## Confusion Matrix

This confusion matrix gives a visualization of correct and incorrect predictions made by the model against the actual, full, dataset. From the plot it is evident the model correctly predicted that the vast majority of subjects had "no-diabetes". It was less successful in predicting "diabetes" among subjects who actually had diabetes.

```{r}

rf_lastfit <- extract_workflow(rf3_final_fit)

predict_ds <- diabetes_model_data |>
    mutate(
      estimate = rf_lastfit |>
        predict(diabetes_model_data) )

matrix <- conf_mat(
  diabetes_model_data |>
    mutate(
      estimate = rf_lastfit |>
        predict(diabetes_model_data) |>
        pull()),
  diabetes_binary_f,
  estimate
    )
matrix
autoplot(matrix)

```

```{r}
#reset plan to default
plan(sequential)
```
